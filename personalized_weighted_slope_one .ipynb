{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and load necesary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "df = pd.read_csv('~/ml-100k/u.data', names=['user_id', 'item_id', 'rating', 'timestamp'], sep='\\t')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset\n",
    "## Random Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n",
      "Construct the rating matrix based on train_df:\n",
      "     0     1     2     3     4     5     6     7     8     9     ...  1672  \\\n",
      "0     0.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   0.0   \n",
      "1     4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  ...   0.0   \n",
      "2     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "3     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "4     4.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "938   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   5.0   0.0  ...   0.0   \n",
      "939   0.0   0.0   0.0   2.0   0.0   0.0   4.0   5.0   3.0   0.0  ...   0.0   \n",
      "940   5.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "941   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "942   0.0   5.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0   0.0  ...   0.0   \n",
      "\n",
      "     1673  1674  1675  1676  1677  1678  1679  1680  1681  \n",
      "0     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "938   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "939   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "940   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "941   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "942   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[943 rows x 1682 columns]\n",
      "Construct the rating matrix based on test_df:\n",
      "     0     1     2     3     4     5     6     7     8     9     ...  1672  \\\n",
      "0     5.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "1     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "2     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "3     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "4     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "938   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "939   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "940   0.0   0.0   0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0  ...   0.0   \n",
      "941   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "942   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "\n",
      "     1673  1674  1675  1676  1677  1678  1679  1680  1681  \n",
      "0     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "938   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "939   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "940   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "941   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "942   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[943 rows x 1682 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "print(str(n_users) + ' users')\n",
    "print(str(n_items) + ' items')\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state = 10)\n",
    "\n",
    "# Training Dataset\n",
    "train_ds = np.zeros((n_users, n_items))\n",
    "for row in train_df.itertuples():\n",
    "    train_ds[row[1]-1, row[2]-1] = row[3]\n",
    "train_ds = pd.DataFrame(train_ds)\n",
    "\n",
    "# Testing Dataset\n",
    "test_ds = np.zeros((n_users, n_items))\n",
    "for row in test_df.itertuples():\n",
    "    test_ds[row[1]-1, row[2]-1] = row[3]\n",
    "test_ds = pd.DataFrame(test_ds)\n",
    "\n",
    "print(\"Construct the rating matrix based on train_df:\")\n",
    "print(train_ds)\n",
    "\n",
    "print(\"Construct the rating matrix based on test_df:\")\n",
    "print(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell\n",
    "EPSILON = 1e-9\n",
    "\n",
    "def evaluate(test_ds, predicted_ds):\n",
    "    '''\n",
    "    Function for evaluating on MAE and RMSE\n",
    "    '''\n",
    "    # MAE\n",
    "    mask_test_ds = test_ds > 0\n",
    "    MAE = np.sum(np.abs(test_ds[mask_test_ds] - predicted_ds[mask_test_ds])) / np.sum(mask_test_ds.astype(np.float32))\n",
    "\n",
    "    # RMSE\n",
    "    RMSE = np.sqrt(np.sum(np.square(test_ds[mask_test_ds] - predicted_ds[mask_test_ds])) / np.sum(mask_test_ds.astype(np.float32)))\n",
    "\n",
    "    return MAE, RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_pearson_corr:\n",
      "[[ 1.          0.5199339   0.16829646 ...  0.50529681 -0.04560263\n",
      "  -0.05569836]\n",
      " [ 0.5199339   1.          0.14726926 ... -0.11386218  0.0846679\n",
      "   0.76751649]\n",
      " [ 0.16829646  0.14726926  1.         ...  0.85049107 -0.31133671\n",
      "   1.        ]\n",
      " ...\n",
      " [ 0.50529681 -0.11386218  0.85049107 ...  1.         -1.\n",
      "   0.01272331]\n",
      " [-0.04560263  0.0846679  -0.31133671 ... -1.          1.\n",
      "   0.4021779 ]\n",
      " [-0.05569836  0.76751649  1.         ...  0.01272331  0.4021779\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Reference: Dr.Yongli Ren (2013), Lecture Class 10 example, KNN_based_CF_Demo.ipynb\n",
    "# Prepare centered cosin similarity\n",
    "GAMMA = 25\n",
    "EPSILON = 1e-9\n",
    "\n",
    "\n",
    "np_user_pearson_corr = np.zeros((n_users, n_users))\n",
    "for i, user_i_vec in enumerate(train_ds.values):\n",
    "    for j, user_j_vec in enumerate(train_ds.values):\n",
    "        \n",
    "        # ratings corated by the current pair of users\n",
    "        mask_i = user_i_vec > 0\n",
    "        mask_j = user_j_vec > 0\n",
    "\n",
    "        # corrated item index, skip if there are no corrated ratings\n",
    "        corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "        if len(corrated_index) == 0:\n",
    "            continue\n",
    "\n",
    "        # average value of user_i_vec and user_j_vec\n",
    "        mean_user_i = np.sum(user_i_vec) / (np.sum(np.clip(user_i_vec, 0, 1)) + EPSILON)\n",
    "        mean_user_j = np.sum(user_j_vec) / (np.sum(np.clip(user_j_vec, 0, 1)) + EPSILON)\n",
    "                \n",
    "        # compute pearson corr\n",
    "        user_i_sub_mean = user_i_vec[corrated_index] - mean_user_i\n",
    "        user_j_sub_mean = user_j_vec[corrated_index] - mean_user_j\n",
    "        \n",
    "        r_ui_sub_r_i_sq = np.square(user_i_sub_mean)\n",
    "        r_uj_sub_r_j_sq = np.square(user_j_sub_mean)\n",
    "\n",
    "        r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "        r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "        \n",
    "        #  centered cosin similarity\n",
    "        sim = np.sum(user_i_sub_mean * user_j_sub_mean) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "\n",
    "        # significance weighting - Use significance weighting if the size of co-rated item set is too small, the corresponding similarity is likely not that reliable.\n",
    "        weighted_sim = sim\n",
    "        #weighted_sim = (min(len(corrated_index), GAMMA) / GAMMA) * sim\n",
    "        #print(\"len(corrated_index) \" + \" is \" + str(len(corrated_index)))\n",
    "        \n",
    "        np_user_pearson_corr[i][j] = weighted_sim\n",
    "        \n",
    "print('user_pearson_corr:')        \n",
    "print(np_user_pearson_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      "[[3.90957736 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "KNN_LAMBDA = 0\n",
    "LAMBDA = 0.5\n",
    "\n",
    "# Slope One Predictors    \n",
    "def slope_one_predictors(i_input, j_input):\n",
    "    dev1 = np.zeros((n_items, n_items))\n",
    "    dev2 = np.zeros((n_items, n_items))\n",
    "    dev = np.zeros((n_items, n_items))\n",
    "    dev_user = np.zeros((n_items, n_items))\n",
    "    for i, item_i_vec in enumerate(train_ds.T.values):\n",
    "        if i == j_input:  # only perfrom prediction for the test_df items\n",
    "            for j, item_j_vec in enumerate(train_ds.T.values):\n",
    "        \n",
    "                if i != j:\n",
    "                    # only include rated users\n",
    "                    mask_i = item_i_vec > 0\n",
    "                    mask_j = item_j_vec > 0\n",
    "                    corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "                    # filter users with KNN concept take users with sim lager than definded value only \n",
    "                    # comment the follow 2 lines if not apply the KNN concept \n",
    "                    corrated_index2 = np.where(np_user_pearson_corr[i_input][corrated_index]>KNN_LAMBDA)[0]\n",
    "                    corrated_index = corrated_index[corrated_index2]\n",
    "                    if len(corrated_index) == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    item_corrated_diff = item_i_vec[corrated_index] - item_j_vec[corrated_index]\n",
    "                    item_corrated_user = len(corrated_index)\n",
    "                    \n",
    "                    # DEV part 1 - get the average difference between the ratings of one item and another\n",
    "                    dev1[i][j] = np.sum(item_corrated_diff)/len(corrated_index)\n",
    "                    dev_user[i][j] = len(corrated_index)\n",
    "        \n",
    "                    # DEV part 2 -  with Centered Cosine Similarity and Rating-Based Collaborative Filtering ( active user = i_input)\n",
    "                    dev2[i][j] = np.sum(np.multiply(item_corrated_diff, np.exp(np_user_pearson_corr[i_input][corrated_index])))/np.sum(np.multiply(len(corrated_index), np.exp(np_user_pearson_corr[i_input][corrated_index])))\n",
    "                    \n",
    "                    # DEV\n",
    "                    dev[i][j] = (LAMBDA * dev1[i][j]) + ((1-LAMBDA) * dev2[i][j])\n",
    "    \n",
    "    \n",
    "    # prediction\n",
    "    pred_wso = np.zeros((n_users, n_items))\n",
    "    for i, user_i_vec in enumerate(train_ds.values):\n",
    "        if i == i_input:  ## only perfrom prediction for the test_df users\n",
    "            rated_index = np.where(user_i_vec>0)[0]\n",
    "        \n",
    "            for n in range(n_items):\n",
    "                if n == j_input:  ## only perfrom prediction for the test_df items\n",
    "                    pred_wso[i][n] = np.sum((dev[n][rated_index] + user_i_vec[rated_index]) * dev_user[n][rated_index]) / np.sum(dev_user[n][rated_index])\n",
    "            \n",
    "    return pred_wso\n",
    "\n",
    "train_test_predictions_result = np.zeros((n_users, n_items))\n",
    "for (i, j), rating in np.ndenumerate(test_ds.values):\n",
    "    if rating > 0:\n",
    "        predictions_result = slope_one_predictors(i,j)\n",
    "        train_test_predictions_result[i][j] = predictions_result[i][j]\n",
    "        \n",
    "print('prediction:')\n",
    "print(train_test_predictions_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      "[[3.90957736 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "labels:\n",
      "[[5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "absolute_error:\n",
      "[[1.09042264 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "weight:\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "abs_error:\n",
      "[[1.09042264 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "MAE:\n",
      "0.7461683679701425\n",
      "RMSE:\n",
      "0.9495673617313544\n"
     ]
    }
   ],
   "source": [
    "# Reference: Dr.Yongli Ren (2013), Lecture Class 10 example, KNN_based_CF_Demo.ipynb\n",
    "EPSILON = 1e-9\n",
    "weight = np.zeros((n_users, n_items))\n",
    "absolute_error = np.zeros((n_users, n_items))\n",
    "abs_error = np.zeros((n_users, n_items))\n",
    "\n",
    "# MAE and RMSE on Testing set\n",
    "print('prediction:')\n",
    "print(train_test_predictions_result)\n",
    "\n",
    "labels = test_ds.values\n",
    "print('labels:')\n",
    "print(labels)\n",
    "\n",
    "absolute_error = np.abs(train_test_predictions_result - labels)\n",
    "print('absolute_error:')\n",
    "print(absolute_error)\n",
    "\n",
    "# weight\n",
    "weight = np.clip(labels, 0, 1)\n",
    "print('weight:')\n",
    "print(weight)\n",
    "\n",
    "# absoulte error on rated ratings\n",
    "abs_error = absolute_error * weight\n",
    "print('abs_error:')\n",
    "print(abs_error)\n",
    "abs_error = np.nan_to_num(abs_error, copy=True, nan=0.0, posinf=None, neginf=None)\n",
    "\n",
    "# MAE\n",
    "MAE = np.sum(abs_error) / np.sum(weight)\n",
    "print('MAE:')\n",
    "print(MAE)\n",
    "\n",
    "\n",
    "# squared error on all ratings\n",
    "squared_error = np.square(train_test_predictions_result - labels)\n",
    "weight = np.clip(labels, 0, 1)\n",
    "\n",
    "# squared error on rated ratings\n",
    "squared_error = squared_error * weight\n",
    "squared_error = np.nan_to_num(squared_error, copy=True, nan=0.0, posinf=None, neginf=None)\n",
    "\n",
    "# RMSE\n",
    "RMSE = np.sqrt(np.sum(squared_error) / np.sum(weight))\n",
    "\n",
    "print('RMSE:')\n",
    "print(RMSE)\n",
    "\n",
    "#MAERMSE = evaluate(labels, train_test_predictions_result)\n",
    "#MAE = MAERMSE[0] \n",
    "#RMSE = MAERMSE[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== The MAE and RMSE of Your Implementation =====================\n",
      "MAE: 0.7461683679701425, RMSE: 0.9495673617313544\n"
     ]
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "print(\"===================== The MAE and RMSE of Your Implementation =====================\")\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE, RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
